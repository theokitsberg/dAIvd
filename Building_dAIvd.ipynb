{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXM6yLc4eiYm"
      },
      "outputs": [],
      "source": [
        "# --- Cell 1: Install and Import Libraries ---\n",
        "\n",
        "# Install Anthropics Claude API SDK if needed\n",
        "!pip install anthropic -q\n",
        "\n",
        "# Core imports\n",
        "import anthropic\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"✅ Libraries installed and imported.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 2: Set Up Claude API Key and Model Config ---\n",
        "\n",
        "# (You can run this cell safely; your key stays private inside the notebook.)\n",
        "\n",
        "import getpass\n",
        "\n",
        "# Enter your Claude API Key securely\n",
        "api_key = getpass.getpass(\"Enter your Claude API key:\")\n",
        "\n",
        "# Initialize the Claude (Anthropic) client\n",
        "client = anthropic.Anthropic(\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# Choose Claude Model\n",
        "model_name = \"claude-3-7-sonnet-20250219\"\n",
        "\n",
        "print(f\"✅ Connected to Claude model: {model_name}\")\n"
      ],
      "metadata": {
        "id": "SkzOZ7M2ewdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 3: Upload the Essays Dataset Manually ---\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Upload Essays.csv manually\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Find uploaded filename\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Load using pandas\n",
        "essays_df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "\n",
        "# Check the first few rows to make sure it's loaded properly\n",
        "print(\"✅ Essays loaded:\")\n",
        "display(essays_df.head())\n",
        "\n",
        "# Convert to list\n",
        "real_essays = essays_df['essay_text'].tolist()\n",
        "\n",
        "# Split essays into Training and Holdout Sets\n",
        "# Reserve last 3 for holdout evaluation\n",
        "training_essays = real_essays[:-3]\n",
        "holdout_essays = real_essays[-3:]\n",
        "\n",
        "print(f\"Training Essays: {len(training_essays)} | Holdout Essays: {len(holdout_essays)}\")\n"
      ],
      "metadata": {
        "id": "APjSGz2xfJ3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 4: Load Philosophical Topics ---\n",
        "\n",
        "# List of philosophical essay topics\n",
        "philosophy_topics = [\n",
        "    # Metaphysics and Philosophy of Mind\n",
        "    \"Is free will compatible with determinism?\",\n",
        "    \"Are personal identities continuous over time?\",\n",
        "    \"Is consciousness fundamentally physical or non-physical?\",\n",
        "    \"Can non-human animals possess minds?\",\n",
        "    \"Do abstract objects, like numbers, really exist?\",\n",
        "\n",
        "    # Ethics and Political Philosophy\n",
        "    \"Are moral facts objective or subjective?\",\n",
        "    \"Can a perfectly just society ever exist?\",\n",
        "    \"Is democracy the best form of government?\",\n",
        "    \"Are individuals morally responsible for the actions of the groups they belong to?\",\n",
        "    \"Is equality more important than liberty?\",\n",
        "\n",
        "    # Epistemology and Theory of Knowledge\n",
        "    \"Can we ever truly know anything with certainty?\",\n",
        "    \"Is perception a reliable guide to reality?\",\n",
        "    \"Is testimony from others a basic source of knowledge?\",\n",
        "    \"How should we deal with disagreement among epistemic peers?\",\n",
        "    \"Is skepticism a rational position?\",\n",
        "\n",
        "    # Philosophy of Science\n",
        "    \"Does scientific progress bring us closer to truth?\",\n",
        "    \"Are scientific theories inventions or discoveries?\",\n",
        "    \"Should science aim for truth or for usefulness?\",\n",
        "    \"Can social sciences be as rigorous as natural sciences?\",\n",
        "    \"What distinguishes science from pseudoscience?\",\n",
        "\n",
        "    # Aesthetics and Philosophy of Art\n",
        "    \"Can art be immoral?\",\n",
        "    \"Is beauty subjective or objective?\",\n",
        "    \"Can a work of art be understood independently of its historical context?\",\n",
        "    \"Should artists have moral responsibilities?\",\n",
        "    \"Can anything be considered 'art'?\",\n",
        "\n",
        "    # General Philosophy\n",
        "    \"Is it possible to have a meaningful life without belief in a higher power?\",\n",
        "    \"Can language ever fully capture reality?\",\n",
        "    \"Should future generations have rights?\",\n",
        "    \"Is progress always desirable?\",\n",
        "    \"What makes an action morally praiseworthy?\"\n",
        "]\n",
        "\n",
        "print(f\"✅ Loaded {len(philosophy_topics)} philosophical topics.\")\n"
      ],
      "metadata": {
        "id": "P7k_7BrKfk1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Retry Helper Function ---\n",
        "\n",
        "import time\n",
        "\n",
        "def with_retry(func, max_retries=3, wait_seconds=5, **kwargs):\n",
        "    \"\"\"Call a function with automatic retries if it fails.\"\"\"\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            return func(**kwargs)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Attempt {attempt} failed with error: {e}\")\n",
        "            if attempt < max_retries:\n",
        "                print(f\"⏳ Waiting {wait_seconds} seconds before retry...\")\n",
        "                time.sleep(wait_seconds)\n",
        "            else:\n",
        "                print(\"❌ Max retries reached. Raising exception.\")\n",
        "                raise e\n"
      ],
      "metadata": {
        "id": "QDWrgJout3QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---  Cell 5: Define the Four Core Agents with Smarter Retry ---\n",
        "\n",
        "# Smarter Retry Helper\n",
        "def with_retry(func, max_retries=5, base_wait_seconds=5, **kwargs):\n",
        "    \"\"\"Call a function with automatic retries if it fails.\"\"\"\n",
        "    for attempt in range(1, max_retries + 1):\n",
        "        try:\n",
        "            return func(**kwargs)\n",
        "        except Exception as e:\n",
        "            error_message = str(e)\n",
        "            print(f\"⚠️ Attempt {attempt} failed with error: {error_message}\")\n",
        "\n",
        "            # Dynamic wait time\n",
        "            if 'overloaded' in error_message.lower():\n",
        "                wait_time = base_wait_seconds * 4  # Longer wait if overloaded\n",
        "                print(f\"⏳ Server overloaded. Waiting {wait_time} seconds before retry...\")\n",
        "            else:\n",
        "                wait_time = base_wait_seconds\n",
        "                print(f\"⏳ Waiting {wait_time} seconds before retry...\")\n",
        "\n",
        "            if attempt < max_retries:\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                print(\"❌ Max retries reached. Raising exception.\")\n",
        "                raise e\n",
        "\n",
        "# 1. Essay Generator (streaming + smarter retry)\n",
        "def generate_essay(system_prompt, topic):\n",
        "    def inner_call(system_prompt, topic):\n",
        "        response = client.messages.create(\n",
        "            model=model_name,\n",
        "            max_tokens=30000,\n",
        "            system=system_prompt,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": f\"Write a philosophical essay on the following topic:\\n\\n{topic}\"}\n",
        "            ],\n",
        "            stream=True\n",
        "        )\n",
        "        full_text = \"\"\n",
        "        for chunk in response:\n",
        "            if chunk.type == \"content_block_delta\":\n",
        "                full_text += chunk.delta.text\n",
        "        return full_text.strip()\n",
        "\n",
        "    return with_retry(inner_call, system_prompt=system_prompt, topic=topic)\n",
        "\n",
        "# 2. Batch Builder (no retry needed)\n",
        "def build_batch(real_essays, generated_essay, batch_size=5):\n",
        "    real_sample = random.sample(real_essays, batch_size - 1)\n",
        "    batch = real_sample + [generated_essay]\n",
        "    random.shuffle(batch)\n",
        "    generated_index = batch.index(generated_essay)\n",
        "    return batch, generated_index\n",
        "\n",
        "# 3. Discriminator (streaming + smarter retry)\n",
        "def discriminate(batch):\n",
        "    def inner_call(batch):\n",
        "        batch_text = \"\\n\\n\".join([f\"Essay {i+1}:\\n{essay}\" for i, essay in enumerate(batch)])\n",
        "        discriminator_prompt = f\"\"\"\n",
        "You are a style analyst.\n",
        "\n",
        "You will read {len(batch)} essays, labeled Essay 1 to Essay {len(batch)}.\n",
        "One essay was written by a different author than the others.\n",
        "\n",
        "Your task:\n",
        "1. Identify which essay is different by **essay number** (1 to {len(batch)}).\n",
        "2. Explain stylistic, argumentative, or tonal differences you observed.\n",
        "3. Suggest changes that would make the different essay match the others.\n",
        "\n",
        "Answer in the following format:\n",
        "\n",
        "Odd Essay Number: [number]\n",
        "Differences Observed: [text]\n",
        "Suggested Improvements: [text]\n",
        "\n",
        "Here are the essays:\n",
        "\n",
        "{batch_text}\n",
        "        \"\"\"\n",
        "        response = client.messages.create(\n",
        "            model=model_name,\n",
        "            max_tokens=20000,\n",
        "            system=\"You are a highly intelligent philosophical essay style analyst.\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": discriminator_prompt}\n",
        "            ],\n",
        "            stream=True\n",
        "        )\n",
        "        full_text = \"\"\n",
        "        for chunk in response:\n",
        "            if chunk.type == \"content_block_delta\":\n",
        "                full_text += chunk.delta.text\n",
        "        return full_text.strip()\n",
        "\n",
        "    return with_retry(inner_call, batch=batch)\n",
        "\n",
        "# 4. Prompt Generator (streaming + smarter retry)\n",
        "def update_prompt(current_prompt, discriminator_feedback):\n",
        "    def inner_call(current_prompt, discriminator_feedback):\n",
        "        prompt_generator_instruction = f\"\"\"\n",
        "You are a prompt engineer helping a philosophical essay writer.\n",
        "\n",
        "Given the following feedback about a style mismatch, rewrite the system prompt to better match the intended style.\n",
        "You may make major changes if necessary.\n",
        "\n",
        "Current System Prompt:\n",
        "{current_prompt}\n",
        "\n",
        "Discriminator Feedback:\n",
        "{discriminator_feedback}\n",
        "\n",
        "Write a revised system prompt:\n",
        "        \"\"\"\n",
        "        response = client.messages.create(\n",
        "            model=model_name,\n",
        "            max_tokens=10000,\n",
        "            system=\"You are an expert prompt engineer specializing in style transfer.\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt_generator_instruction}\n",
        "            ],\n",
        "            stream=True\n",
        "        )\n",
        "        full_text = \"\"\n",
        "        for chunk in response:\n",
        "            if chunk.type == \"content_block_delta\":\n",
        "                full_text += chunk.delta.text\n",
        "        return full_text.strip()\n",
        "\n",
        "    return with_retry(inner_call, current_prompt=current_prompt, discriminator_feedback=discriminator_feedback)\n"
      ],
      "metadata": {
        "id": "WH46mzKsgtAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 6: Define Assessment Logic ---\n",
        "\n",
        "import re\n",
        "\n",
        "def parse_discriminator_feedback(feedback_text):\n",
        "    \"\"\"Extracts guessed essay number, differences observed, and suggestions from discriminator's output.\"\"\"\n",
        "    try:\n",
        "        # Try to extract using regular expressions\n",
        "        odd_essay_match = re.search(r\"Odd Essay Number:\\s*(\\d+)\", feedback_text)\n",
        "        differences_match = re.search(r\"Differences Observed:\\s*(.*?)(?:Suggested Improvements:|$)\", feedback_text, re.DOTALL)\n",
        "        suggestions_match = re.search(r\"Suggested Improvements:\\s*(.*)\", feedback_text, re.DOTALL)\n",
        "\n",
        "        if odd_essay_match:\n",
        "            guessed_index = int(odd_essay_match.group(1)) - 1  # Convert to 0-based indexing\n",
        "        else:\n",
        "            guessed_index = None\n",
        "\n",
        "        differences = differences_match.group(1).strip() if differences_match else \"\"\n",
        "        suggestions = suggestions_match.group(1).strip() if suggestions_match else \"\"\n",
        "\n",
        "        return guessed_index, differences, suggestions\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error parsing discriminator feedback: {e}\")\n",
        "        return None, \"\", \"\"\n",
        "\n",
        "def assess_discriminator(generated_index, guessed_index):\n",
        "    \"\"\"Returns True if discriminator succeeded, else False.\"\"\"\n",
        "    return generated_index == guessed_index\n"
      ],
      "metadata": {
        "id": "6davCLkYhLpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 7: Main RPO Control Loop ---\n",
        "\n",
        "# Initialize the starting system prompt\n",
        "current_prompt = \"You are a philosophical essayist. Write essays with clear reasoning, personal voice, and dialectical progression.\"\n",
        "\n",
        "# Set how many total iterations you want\n",
        "total_iterations = 50  # You can adjust easily\n",
        "\n",
        "# Set batch size scaling stages\n",
        "def dynamic_batch_size(iteration):\n",
        "    if iteration <= 15:\n",
        "        return 5  # Start small for tight early corrections\n",
        "    elif iteration <= 30:\n",
        "        return 7  # Mid-game slightly larger batches\n",
        "    else:\n",
        "        return 15  # Late-game large batches for subtle blending\n",
        "\n",
        "# Initialize tracking\n",
        "history = []\n",
        "feedback_memory = []\n",
        "failure_streak = 0\n",
        "failure_streak_limit = 3  # Stop if discriminator fails 3 times in a row\n",
        "\n",
        "for iteration in range(1, total_iterations + 1):\n",
        "    print(f\"\\n🌀 Iteration {iteration} starting...\")\n",
        "\n",
        "    # 1. Pick a random philosophical topic\n",
        "    topic = random.choice(philosophy_topics)\n",
        "\n",
        "    # 2. Generate essay with current prompt\n",
        "    print(f\"📝 Generating essay on topic: {topic}\")\n",
        "    generated_essay = generate_essay(current_prompt, topic)\n",
        "\n",
        "    # 3. Determine batch size dynamically\n",
        "    batch_size = dynamic_batch_size(iteration)\n",
        "    print(f\"📚 Batch size for this iteration: {batch_size} essays\")\n",
        "\n",
        "    batch, generated_index = build_batch(training_essays, generated_essay, batch_size=batch_size)\n",
        "\n",
        "    # 4. Discriminate\n",
        "    print(\"🔎 Discriminator analyzing batch...\")\n",
        "    raw_feedback = discriminate(batch)\n",
        "\n",
        "    # 5. Parse Discriminator feedback\n",
        "    guessed_index, differences, suggestions = parse_discriminator_feedback(raw_feedback)\n",
        "\n",
        "    # 6. Assess success\n",
        "    if guessed_index is not None and assess_discriminator(generated_index, guessed_index):\n",
        "        print(\"✅ Discriminator SUCCESS! Updating prompt...\")\n",
        "        failure_streak = 0  # Reset streak\n",
        "\n",
        "        # Add latest suggestions to memory\n",
        "        feedback_memory.append(suggestions)\n",
        "\n",
        "        # Combine all feedback to give prompt generator full history\n",
        "        all_feedback = \"\\n\\n\".join(feedback_memory)\n",
        "\n",
        "        # Update system prompt\n",
        "        current_prompt = update_prompt(current_prompt, all_feedback)\n",
        "        success = True\n",
        "    else:\n",
        "        print(\"❌ Discriminator FAILURE. Keeping current prompt...\")\n",
        "        failure_streak += 1\n",
        "        success = False\n",
        "\n",
        "    # 7. Save history\n",
        "    history.append({\n",
        "        \"iteration\": iteration,\n",
        "        \"topic\": topic,\n",
        "        \"generated_essay\": generated_essay,\n",
        "        \"generated_index\": generated_index,\n",
        "        \"guessed_index\": guessed_index,\n",
        "        \"success\": success,\n",
        "        \"differences\": differences,\n",
        "        \"suggestions\": suggestions,\n",
        "        \"system_prompt_before\": current_prompt,  # Save real current prompt\n",
        "    })\n",
        "\n",
        "    # 8. Check stop condition\n",
        "    if failure_streak >= failure_streak_limit:\n",
        "        print(\"\\n🎯 Discriminator failed 3 times consecutively. Stopping RPO.\")\n",
        "        break\n",
        "\n",
        "    # Small delay for API safety\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"\\n🏁 RPO Training Finished!\")\n"
      ],
      "metadata": {
        "id": "UTXQ4bA1hVXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell 8: Display and Summarize RPO Findings ---\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the RPO history list to a pandas DataFrame\n",
        "rpo_history_df = pd.DataFrame(history)\n",
        "\n",
        "# Display the first few rows to inspect\n",
        "print(\"📝 Full RPO Iteration History:\")\n",
        "display(rpo_history_df)\n",
        "\n",
        "# Success rate calculation\n",
        "total_iters = len(rpo_history_df)\n",
        "total_success = rpo_history_df['success'].sum()\n",
        "success_rate = (total_success / total_iters) * 100\n",
        "\n",
        "print(f\"\\n📊 Summary Statistics:\")\n",
        "print(f\"Total Iterations Completed: {total_iters}\")\n",
        "print(f\"Total Successes (Discriminator Correct): {total_success}\")\n",
        "print(f\"Success Rate: {success_rate:.2f}%\")\n",
        "\n",
        "# Display last 5 system prompts if available\n",
        "if 'system_prompt_before' in rpo_history_df.columns:\n",
        "    print(\"\\n🧠 Last 5 System Prompts (before update or freeze):\")\n",
        "    last_prompts = rpo_history_df['system_prompt_before'].dropna().tail(5)\n",
        "    for idx, prompt in enumerate(last_prompts, 1):\n",
        "        print(f\"\\nPrompt {idx}:\\n{prompt}\\n{'-'*50}\")\n"
      ],
      "metadata": {
        "id": "AprhWYyMo4W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title iteration vs guessed_index\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "def _plot_series(series, series_name, series_index=0):\n",
        "  palette = list(sns.palettes.mpl_palette('Dark2'))\n",
        "  xs = series['iteration']\n",
        "  ys = series['guessed_index']\n",
        "\n",
        "  plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')\n",
        "df_sorted = rpo_history_df.sort_values('iteration', ascending=True)\n",
        "for i, (series_name, series) in enumerate(df_sorted.groupby('success')):\n",
        "  _plot_series(series, series_name, i)\n",
        "  fig.legend(title='success', bbox_to_anchor=(1, 1), loc='upper left')\n",
        "sns.despine(fig=fig, ax=ax)\n",
        "plt.xlabel('iteration')\n",
        "_ = plt.ylabel('guessed_index')"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "u3E8DLYPzYbC"
      }
    }
  ]
}